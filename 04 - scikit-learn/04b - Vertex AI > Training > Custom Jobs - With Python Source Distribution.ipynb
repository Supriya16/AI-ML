{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d78964",
   "metadata": {},
   "source": [
    "# 04b - Vertex AI > Training > Custom Jobs - With Python Source Distribution\n",
    "\n",
    "*This notebook was developed in collaboration with [statmike](https://github.com/statmike), basing much of the core code from existing notebooks and extending to new features. Notebook author: [goodrules](https://github.com/goodrules)*\n",
    "\n",
    "### 04 Series Overview\n",
    "Where a model gets trained is where it consumes computing resources.  With Vertex AI, you have choices for configuring the computing resources available at training.  This notebook is an example of an execution environment.  When it was set up there were choices for machine type and accelerators (GPUs).  \n",
    "\n",
    "In the `04` notebook, the model training happened directly in the notebook.  The models were then imported to Vertex AI and deployed to an endpoint for online predictions. \n",
    "\n",
    "In this `04a-04i` series of demonstrations, the same model is trained using managed computing resources in Vertex AI as custom training jobs.  These jobs will be demonstrated as:\n",
    "\n",
    "-  Custom Job from a python script (`04a`), python source distribution (`04b`), and custom container (`04c`)\n",
    "-  Training Pipeline that trains and saves models from a python script (`04d`), python source distribution (`04e`), and custom container (`04f`)\n",
    "-  Hyperparameter Tuning Jobs from a python script (`04g`), python source distribution (`04h`), and custom container (`04i`)\n",
    "\n",
    "### This Notebook (`04b`): An extension of `04a` that saves the script within a source distribution\n",
    "This notebook trains the same Tensorflow Keras model from `04` by first modifying and saving the training code to a python script (same as `04a`).  Then a Python source distribution is built containing the script.  While this example fits nicely in a single script, larger examples will benefit from the flexibility offered by source distributions and this notebook gives an example of making the shift.  \n",
    "\n",
    "The source distribution is then used as an input for a Vertex AI > Training > Custom Job that is also assigned compute resources and a [pre-built container for custom training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers) for executing the training in a managed service.  This is done with the [Vertex AI Python SDK](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#) using the class [`aiplatform.CustomJob()`](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomJob).\n",
    "\n",
    "<img src=\"architectures/overview/Training.png\">\n",
    "\n",
    "### Prerequisites:\n",
    "-  01 - BigQuery - Table Data Source\n",
    "-  Understanding:\n",
    "    -  04 - Vertex AI > Notebooks - Models Built in Notebooks with sklearn\n",
    "        -  Contains a more granular review of the sklearn model training\n",
    "\n",
    "### Overview:\n",
    "-  Setup\n",
    "-  Create a `train.py` Python script that recreates the local training in 04\n",
    "-  Build a Python source distribution that contains the `train.py` script\n",
    "-  Use Python Client google.cloud.aiplatform for Vertex AI\n",
    "   -  Custom training job with aiplatform.CustomJob.from_local_script\n",
    "      -  Run job with .run\n",
    "   -  Upload Model to Vertex AI with aiplatform.Model.upload\n",
    "   -  Create Endpoint with Vertex AI with aiplatform.Endpoint.create\n",
    "      -  Deploy model to endpoint with .deploy \n",
    "-  Online Prediction demonstrated using Vertex AI Endpoint with deployed model\n",
    "   -  Get records to score from BigQuery table\n",
    "   -  Prediction with aiplatform.Endpoint.predict\n",
    "   -  Prediction with REST\n",
    "   -  Prediction with gcloud (CLI)\n",
    "\n",
    "### Resources:\n",
    "-  [sklearn](https://scikit-learn.org/stable/)\n",
    "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "-  [Python Client for Vertex AI](https://googleapis.dev/python/aiplatform/latest/aiplatform.html)\n",
    "-  [Create a Python source distribution](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container) for a Vertex AI custom training job\n",
    "-  Containers for training (Pre-Built)\n",
    "   -  [Overview](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)\n",
    "   -  [List](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a804cd0",
   "metadata": {},
   "source": [
    "-----\n",
    "## Vertex AI - Conceptual Flow\n",
    "\n",
    "<img src=\"architectures/slides/04b_arch.png\">\n",
    "\n",
    "---\n",
    "## Vertex AI - Workflow\n",
    "\n",
    "<img src=\"architectures/slides/04b_console.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d7ebf",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bdd154",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2576cd17-652d-4c1f-a2f8-c779c98e4f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mg-ce-demos'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6611c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "DATANAME = 'fraud'\n",
    "NOTEBOOK = '04b'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_IMAGE = 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-23:latest'\n",
    "TRAIN_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/scikit-learn-cpu.0-23:latest'\n",
    "SKLEARN_VERSION = '0.23'\n",
    "TRAIN_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id Class splits'\n",
    "C = '1.0' # based on 'best' model from notebook 04\n",
    "SOLVER = 'newton-cg' # based on 'best' model from notebook 04\n",
    "PENALTY = 'l2' # based on 'best' model from notebook 04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b74b1c3",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6d8f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a272b713",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7f1739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bigquery = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e4bd8",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dc3c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "BLOB = f\"{DATANAME}/models/{NOTEBOOK}/{TIMESTAMP}/model/model.joblib\"\n",
    "URI = f\"gs://{BUCKET}/{DATANAME}/models/{NOTEBOOK}\"\n",
    "DIR = f\"temp/{NOTEBOOK}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77b168fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mg-ce-demos-main@mg-ce-demos.iam.gserviceaccount.com'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give service account roles/storage.objectAdmin permissions\n",
    "# Console > IMA > Select Account <projectnumber>-compute@developer.gserviceaccount.com > edit - give role\n",
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c84ba",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39df5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a616e2",
   "metadata": {},
   "source": [
    "---\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1c9ac",
   "metadata": {},
   "source": [
    "### Assemble Python File for Training\n",
    "\n",
    "Create the main python trainer file as `/train.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bd605d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {DIR}/source/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d10cef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp/04b/source/trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/source/trainer/train.py\n",
    "\n",
    "# package import\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import json\n",
    "\n",
    "# import argument to local variables\n",
    "parser = argparse.ArgumentParser()\n",
    "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
    "parser.add_argument('--c_value', dest = 'c_value', default = 1.0, type = float, help = 'C value')\n",
    "parser.add_argument('--penalty', dest = 'penalty', default = 'l2', type = str, help = 'Penalty term')\n",
    "parser.add_argument('--solver', dest = 'solver', default = 'newton-cg', type = str, help = 'Logistic regression solver')\n",
    "parser.add_argument('--var_target', dest = 'var_target', type=str)\n",
    "parser.add_argument('--var_omit', dest = 'var_omit', type=str)\n",
    "parser.add_argument('--project_id', dest = 'project_id', type=str)\n",
    "parser.add_argument('--dataname', dest = 'dataname', type=str)\n",
    "parser.add_argument('--region', dest = 'region', type=str)\n",
    "parser.add_argument('--notebook', dest = 'notebook', type=str)\n",
    "parser.add_argument('--bucket', dest = 'bucket', type=str)\n",
    "parser.add_argument('--blob', dest = 'blob', type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# built in parameters for data source:\n",
    "PROJECT_ID = args.project_id\n",
    "DATANAME = args.dataname\n",
    "REGION = args.region\n",
    "NOTEBOOK = args.notebook\n",
    "BUCKET = args.bucket\n",
    "BLOB = args.blob\n",
    "VAR_OMIT = str(args.var_omit).split(' ')\n",
    "\n",
    "# clients\n",
    "bigquery = bigquery.Client(project = PROJECT_ID)\n",
    "\n",
    "# get schema from bigquery source\n",
    "query = f\"SELECT * FROM {DATANAME}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{DATANAME}_prepped'\"\n",
    "schema = bigquery.query(query).to_dataframe()\n",
    "\n",
    "# get number of classes from bigquery source\n",
    "nclasses = bigquery.query(query = f'SELECT DISTINCT {args.var_target} FROM {DATANAME}.{DATANAME}_prepped WHERE {args.var_target} is not null').to_dataframe()\n",
    "nclasses = nclasses.shape[0]\n",
    "\n",
    "# read datasets from BigQuery\n",
    "train_query = f\"SELECT * FROM {DATANAME}.{DATANAME}_prepped WHERE splits = 'TRAIN'\"\n",
    "train = bigquery.query(train_query).to_dataframe()\n",
    "X_train = train.loc[:, ~train.columns.isin(VAR_OMIT)]\n",
    "y_train = train[args.var_target]\n",
    "\n",
    "# Logistic Regression\n",
    "clf = LogisticRegression(C=args.c_value, penalty=args.penalty, solver=args.solver, random_state=18) #optimal hyperparameters from GridSearchCV - see notebook 04\n",
    "model = clf.fit(X_train, y_train)\n",
    "\n",
    "# Output model file\n",
    "joblib.dump(model, 'model.joblib') # the model needs to be named model.joblib is order for model upload to be successful\n",
    "\n",
    "# Upload the model to GCS\n",
    "bucket = storage.Client().bucket(BUCKET)\n",
    "blob = bucket.blob(BLOB)\n",
    "blob.upload_from_filename('model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea53db8",
   "metadata": {},
   "source": [
    "### Assemble Python Source Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b9a32",
   "metadata": {},
   "source": [
    "create `setup.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7a0d72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp/04b/source/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/source/setup.py\n",
    "from setuptools import setup\n",
    "from setuptools import find_packages\n",
    "\n",
    "REQUIRED_PACKAGES = ['sklearn']\n",
    "\n",
    "setup(\n",
    "    name = 'trainer',\n",
    "    version = '0.1',\n",
    "    install_requires = REQUIRED_PACKAGES, \n",
    "    packages = find_packages(),\n",
    "    include_package_data = True,\n",
    "    description='Training Package'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471595dd",
   "metadata": {},
   "source": [
    "add `__init__.py` file to the trainer modules folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f757ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch {DIR}/source/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12335d6",
   "metadata": {},
   "source": [
    "Create the source distribution and copy it to the projects storage bucket:\n",
    "- change to the local direcory with the source folder\n",
    "- remove any previous distributions\n",
    "- tar and gzip the source folder\n",
    "- copy the distribution to the project folder on GCS\n",
    "- change back to the local project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eefb827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mikegoodman/Documents/developer/git_repos/vertex-ai-mlops/04 - scikit-learn/temp/04b\n",
      "a source\n",
      "a source/setup.py\n",
      "a source/trainer\n",
      "a source/trainer/__init__.py\n",
      "a source/trainer/train.py\n",
      "Copying file://source.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  1.7 KiB/  1.7 KiB]                                                \n",
      "Operation completed over 1 objects/1.7 KiB.                                      \n",
      "/Users/mikegoodman/Documents/developer/git_repos/vertex-ai-mlops/04 - scikit-learn\n"
     ]
    }
   ],
   "source": [
    "%cd {DIR}\n",
    "\n",
    "!rm -f source.tar source.tar.gz\n",
    "!tar cvf source.tar source\n",
    "!gzip source.tar\n",
    "!gsutil cp source.tar.gz {URI}/{TIMESTAMP}/source.tar.gz\n",
    "\n",
    "temp = '../'*(DIR.count('/')+1)\n",
    "%cd {temp}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd6879",
   "metadata": {},
   "source": [
    "### Setup Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97fbcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--c_value=\" + C,\n",
    "    \"--penalty=\" + PENALTY,\n",
    "    \"--solver=\" + SOLVER,\n",
    "    \"--var_target=\" + VAR_TARGET,\n",
    "    \"--var_omit=\" + VAR_OMIT,\n",
    "    \"--project_id=\" + PROJECT_ID,\n",
    "    \"--dataname=\" + DATANAME,\n",
    "    \"--region=\" + REGION,\n",
    "    \"--notebook=\" + NOTEBOOK,\n",
    "    \"--bucket=\" + BUCKET,\n",
    "    \"--blob=\" + BLOB\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00454c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_SPEC = {\n",
    "    \"machine_type\": TRAIN_COMPUTE,\n",
    "    \"accelerator_count\": 0\n",
    "}\n",
    "\n",
    "WORKER_POOL_SPEC = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": MACHINE_SPEC,\n",
    "        \"python_package_spec\": {\n",
    "            \"executor_image_uri\": TRAIN_IMAGE,\n",
    "            \"package_uris\": [f\"{URI}/{TIMESTAMP}/source.tar.gz\"],\n",
    "            \"python_module\": \"trainer.train\",\n",
    "            \"args\": CMDARGS\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abc03d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customJob = aiplatform.CustomJob(\n",
    "    display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    worker_pool_specs = WORKER_POOL_SPEC,\n",
    "    base_output_dir = f\"{URI}/{TIMESTAMP}\",\n",
    "    staging_bucket = f\"{URI}/{TIMESTAMP}\",\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c872fe95",
   "metadata": {},
   "source": [
    "### Run Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6a057ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/633472233130/locations/us-central1/customJobs/1317156381081468928\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/633472233130/locations/us-central1/customJobs/1317156381081468928')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/1317156381081468928?project=633472233130\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/633472233130/locations/us-central1/customJobs/1317156381081468928 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "CustomJob run completed. Resource name: projects/633472233130/locations/us-central1/customJobs/1317156381081468928\n"
     ]
    }
   ],
   "source": [
    "customJob.run(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c0a414a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04b_fraud_20221018094605'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customJob.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c210e56",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e81034",
   "metadata": {},
   "source": [
    "### Upload The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e651232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new model, creating in model registry\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/633472233130/locations/us-central1/models/model_04b_fraud/operations/1060595856819879936\n",
      "Model created. Resource name: projects/633472233130/locations/us-central1/models/3476739329911422976@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/633472233130/locations/us-central1/models/3476739329911422976@1')\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name=\"{NOTEBOOK}_{DATANAME}\"')\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if f'time-{TIMESTAMP}' in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        model = aiplatform.Model.upload(\n",
    "            display_name = f'{NOTEBOOK}_{DATANAME}',\n",
    "            model_id = f'model_{NOTEBOOK}_{DATANAME}',\n",
    "            parent_model =  modelmatch[0].resource_name,\n",
    "            serving_container_image_uri = DEPLOY_IMAGE,\n",
    "            artifact_uri = f\"{URI}/{TIMESTAMP}/model\",\n",
    "            is_default_version = True,\n",
    "            version_aliases = [f'time-{TIMESTAMP}'],\n",
    "            version_description = f'time-{TIMESTAMP}',\n",
    "            labels = {'notebook':f'{NOTEBOOK}'}        \n",
    "        )\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name = f'{NOTEBOOK}_{DATANAME}',\n",
    "        model_id = f'model_{NOTEBOOK}_{DATANAME}',\n",
    "        serving_container_image_uri = DEPLOY_IMAGE,\n",
    "        artifact_uri = f\"{URI}/{TIMESTAMP}/model\",\n",
    "        is_default_version = True,\n",
    "        version_aliases = [f'time-{TIMESTAMP}'],\n",
    "        version_description = f'time-{TIMESTAMP}',\n",
    "        labels = {'notebook':f'{NOTEBOOK}'}\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969c42c-c198-466e-abc0-ef47ef4fb034",
   "metadata": {},
   "source": [
    "**Note** on Version Aliases:\n",
    ">Expectation is a name starting with `a-z` that can include `[a-zA-Z0-9-]`\n",
    "\n",
    "**Retrieve a Model Resource**\n",
    "\n",
    "[Resource](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model)\n",
    "```Python\n",
    "model = aiplatform.Model(model_name = f'model_{NOTEBOOK}_{DATANAME}') # retrieves default version\n",
    "model = aiplatform.Model(model_name = f'model_{NOTEBOOK}_{DATANAME}@time-{TIMESTAMP}') # retrieves specific version\n",
    "model = aiplatform.Model(model_name = f'model_{NOTEBOOK}_{DATANAME}', version = f'time-{TIMESTAMP}') # retrieves specific version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc03c5",
   "metadata": {},
   "source": [
    "### Create An Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ae1356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Exists: projects/633472233130/locations/us-central1/endpoints/8704041908730593280\n"
     ]
    }
   ],
   "source": [
    "SERIES = ''.join(filter(str.isdigit, NOTEBOOK))\n",
    "endpoints = aiplatform.Endpoint.list(filter = f\"display_name={SERIES}_{DATANAME}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}_{DATANAME}\",\n",
    "        labels = {'notebook':f\"{SERIES}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d141eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04_fraud'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e519b8",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f541b250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model with 100% of traffic...\n",
      "Deploying Model projects/633472233130/locations/us-central1/models/3476739329911422976 to Endpoint : projects/633472233130/locations/us-central1/endpoints/8704041908730593280\n",
      "Deploy Endpoint model backing LRO: projects/633472233130/locations/us-central1/endpoints/8704041908730593280/operations/5742087669471510528\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "Operation did not complete within the designated timeout.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    945\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"No route to host\"\n\tdebug_error_string = \"{\"created\":\"@1666101524.109221000\",\"description\":\"Error received from peer ipv6:[2607:f8b0:4002:c09::5f]:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":967,\"grpc_message\":\"No route to host\",\"grpc_status\":14}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: 503 No route to host",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36m_blocking_poll\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDEFAULT_RETRY\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"retry\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mretry_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_or_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRetryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m             )\n\u001b[0;32m--> 283\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    284\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36m_done_or_raise\u001b[0;34m(self, retry)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0m_OperationNotComplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/operation.py\u001b[0m in \u001b[0;36mdone\u001b[0;34m(self, retry)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \"\"\"\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refresh_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_operation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/operation.py\u001b[0m in \u001b[0;36m_refresh_and_update\u001b[0;34m(self, retry)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_operation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_operation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_result_from_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/operations_v1/operations_client.py\u001b[0m in \u001b[0;36mget_operation\u001b[0;34m(self, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         return self._get_operation(\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m             )\n\u001b[0;32m--> 283\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    284\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeadline_datetime\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 raise exceptions.RetryError(\n\u001b[0m\u001b[1;32m    206\u001b[0m                     \"Deadline of {:.1f}s exceeded while calling target function\".format(\n",
      "\u001b[0;31mRetryError\u001b[0m: Deadline of 120.0s exceeded while calling target function, last exception: 503 No route to host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q8/1gf829m141157nbz7kc4_19h00tb0q/T/ipykernel_75800/3857302665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Deploying model with 100% of traffic...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     endpoint.deploy(\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdeployed_model_display_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{NOTEBOOK}_{DATANAME}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, model, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, service_account, explanation_metadata, explanation_parameters, metadata, sync, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle)\u001b[0m\n\u001b[1;32m    813\u001b[0m         )\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         self._deploy(\n\u001b[0m\u001b[1;32m    816\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mdeployed_model_display_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeployed_model_display_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36m_deploy\u001b[0;34m(self, model, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, service_account, explanation_metadata, explanation_parameters, metadata, sync, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle)\u001b[0m\n\u001b[1;32m    940\u001b[0m         )\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         self._deploy_call(\n\u001b[0m\u001b[1;32m    943\u001b[0m             \u001b[0mapi_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mendpoint_resource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36m_deploy_call\u001b[0;34m(cls, api_client, endpoint_resource_name, model, endpoint_resource_traffic_split, network, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, service_account, explanation_metadata, explanation_parameters, metadata, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle)\u001b[0m\n\u001b[1;32m   1231\u001b[0m         )\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0moperation_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     def undeploy(\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[1;32m    131\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDEFAULT_RETRY\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"retry\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36m_blocking_poll\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mretry_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_or_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRetryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             raise concurrent.futures.TimeoutError(\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0;34m\"Operation did not complete within the designated \"\u001b[0m \u001b[0;34m\"timeout.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             )\n",
      "\u001b[0;31mTimeoutError\u001b[0m: Operation did not complete within the designated timeout."
     ]
    }
   ],
   "source": [
    "dmodels = endpoint.list_models()\n",
    "\n",
    "check = 0\n",
    "if dmodels:\n",
    "    for dmodel in dmodels:\n",
    "        if dmodel.model == model.resource_name and dmodel.model_version_id == model.version_id and dmodel.id in endpoint.traffic_split:\n",
    "            print(f'This model (and version) already deployed with {endpoint.traffic_split[dmodel.id]}% of traffic')\n",
    "            check = 1\n",
    "    \n",
    "if check == 0:\n",
    "    print(f'Deploying model with 100% of traffic...')\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = f'{NOTEBOOK}_{DATANAME}',\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = DEPLOY_COMPUTE,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d307562-145f-493c-b7ca-2dc16d892a29",
   "metadata": {},
   "source": [
    "### Remove Deployed Models without Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d19a93c3-b2ea-4d9e-b50c-d1f69d471efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/1026793852137/locations/us-central1/endpoints/7252545822577917952\n",
      "Undeploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/7252545822577917952/operations/1435979297025163264\n",
      "Endpoint model undeployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/7252545822577917952\n",
      "Undeployed 05_fraud version 1 as it has no traffic.\n",
      "Model 05b_fraud has traffic = 100\n"
     ]
    }
   ],
   "source": [
    "for dmodel in endpoint.list_models():\n",
    "    if dmodel.id in endpoint.traffic_split:\n",
    "        print(f\"Model {dmodel.display_name} has traffic = {endpoint.traffic_split[dmodel.id]}\")\n",
    "    else:\n",
    "        endpoint.undeploy(deployed_model_id = dmodel.id)\n",
    "        print(f\"Undeployed {dmodel.display_name} version {dmodel.model_version_id} as it has no traffic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c39b02c8-e6bb-410e-83dd-16adcc22c004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4876048196163338240': 100}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1ea870a-ca35-466b-adf6-97f167b0e497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"4876048196163338240\"\n",
       " model: \"projects/633472233130/locations/us-central1/models/model_04b_fraud\"\n",
       " display_name: \"04b_fraud\"\n",
       " create_time {\n",
       "   seconds: 1666101055\n",
       "   nanos: 139600000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"n1-standard-4\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " model_version_id: \"1\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a08a7",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f77a9",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68ee002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = f\"SELECT * FROM {DATANAME}.{DATANAME}_prepped WHERE splits = 'TEST' LIMIT 10\"\n",
    "test = bigquery.query(test_query).to_dataframe()\n",
    "X_test = test.loc[:, ~test.columns.isin(str(VAR_OMIT).split(' '))]\n",
    "y_test = test[VAR_TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6f9761a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15689</td>\n",
       "      <td>-0.745436</td>\n",
       "      <td>1.208740</td>\n",
       "      <td>2.418708</td>\n",
       "      <td>3.033260</td>\n",
       "      <td>-0.501836</td>\n",
       "      <td>1.497792</td>\n",
       "      <td>-0.848100</td>\n",
       "      <td>0.999515</td>\n",
       "      <td>0.376560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149698</td>\n",
       "      <td>-0.066289</td>\n",
       "      <td>0.035959</td>\n",
       "      <td>-0.088377</td>\n",
       "      <td>-0.395340</td>\n",
       "      <td>-0.422684</td>\n",
       "      <td>0.188265</td>\n",
       "      <td>0.020712</td>\n",
       "      <td>0.045274</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51457</td>\n",
       "      <td>-5.194546</td>\n",
       "      <td>-1.741200</td>\n",
       "      <td>2.409787</td>\n",
       "      <td>3.979815</td>\n",
       "      <td>4.745377</td>\n",
       "      <td>-0.470931</td>\n",
       "      <td>-6.630054</td>\n",
       "      <td>-1.774991</td>\n",
       "      <td>0.541608</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.728441</td>\n",
       "      <td>-1.909447</td>\n",
       "      <td>0.063879</td>\n",
       "      <td>-5.298245</td>\n",
       "      <td>-0.242950</td>\n",
       "      <td>-1.611578</td>\n",
       "      <td>0.186398</td>\n",
       "      <td>0.421281</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152527</td>\n",
       "      <td>2.019771</td>\n",
       "      <td>0.058431</td>\n",
       "      <td>-1.041463</td>\n",
       "      <td>1.626049</td>\n",
       "      <td>0.227237</td>\n",
       "      <td>-0.196559</td>\n",
       "      <td>-0.130095</td>\n",
       "      <td>-0.015467</td>\n",
       "      <td>-0.944086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186591</td>\n",
       "      <td>0.191799</td>\n",
       "      <td>0.445460</td>\n",
       "      <td>0.204942</td>\n",
       "      <td>0.859635</td>\n",
       "      <td>-0.411058</td>\n",
       "      <td>2.328281</td>\n",
       "      <td>-0.226044</td>\n",
       "      <td>-0.090710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134025</td>\n",
       "      <td>2.101359</td>\n",
       "      <td>-0.885248</td>\n",
       "      <td>-0.019706</td>\n",
       "      <td>-0.810424</td>\n",
       "      <td>-1.429294</td>\n",
       "      <td>-0.832277</td>\n",
       "      <td>-1.110466</td>\n",
       "      <td>-0.093680</td>\n",
       "      <td>-0.347834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022980</td>\n",
       "      <td>0.493235</td>\n",
       "      <td>1.524276</td>\n",
       "      <td>0.188728</td>\n",
       "      <td>0.619306</td>\n",
       "      <td>-0.262769</td>\n",
       "      <td>-0.123342</td>\n",
       "      <td>0.023263</td>\n",
       "      <td>-0.048398</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161647</td>\n",
       "      <td>-0.484457</td>\n",
       "      <td>1.664356</td>\n",
       "      <td>1.947575</td>\n",
       "      <td>4.371354</td>\n",
       "      <td>0.613689</td>\n",
       "      <td>0.689506</td>\n",
       "      <td>0.536490</td>\n",
       "      <td>-0.021216</td>\n",
       "      <td>-2.204157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242229</td>\n",
       "      <td>0.374826</td>\n",
       "      <td>1.234508</td>\n",
       "      <td>-0.614699</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.583962</td>\n",
       "      <td>0.825513</td>\n",
       "      <td>-0.023025</td>\n",
       "      <td>0.073964</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   15689 -0.745436  1.208740  2.418708  3.033260 -0.501836  1.497792   \n",
       "1   51457 -5.194546 -1.741200  2.409787  3.979815  4.745377 -0.470931   \n",
       "2  152527  2.019771  0.058431 -1.041463  1.626049  0.227237 -0.196559   \n",
       "3  134025  2.101359 -0.885248 -0.019706 -0.810424 -1.429294 -0.832277   \n",
       "4  161647 -0.484457  1.664356  1.947575  4.371354  0.613689  0.689506   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0 -0.848100  0.999515  0.376560  ... -0.149698 -0.066289  0.035959 -0.088377   \n",
       "1 -6.630054 -1.774991  0.541608  ... -1.728441 -1.909447  0.063879 -5.298245   \n",
       "2 -0.130095 -0.015467 -0.944086  ... -0.186591  0.191799  0.445460  0.204942   \n",
       "3 -1.110466 -0.093680 -0.347834  ...  0.022980  0.493235  1.524276  0.188728   \n",
       "4  0.536490 -0.021216 -2.204157  ...  0.242229  0.374826  1.234508 -0.614699   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0 -0.395340 -0.422684  0.188265  0.020712  0.045274     0.0  \n",
       "1 -0.242950 -1.611578  0.186398  0.421281  0.010040     0.0  \n",
       "2  0.859635 -0.411058  2.328281 -0.226044 -0.090710     0.0  \n",
       "3  0.619306 -0.262769 -0.123342  0.023263 -0.048398     0.0  \n",
       "4  0.000011  0.583962  0.825513 -0.023025  0.073964     0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a693e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [X_test.to_dict(orient='split')['data'][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08559ba0",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9582e4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[0.0], deployed_model_id='4876048196163338240', model_version_id='1', model_resource_name='projects/633472233130/locations/us-central1/models/model_04b_fraud', explanations=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances=instances)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44142381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d4d2086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e079bc",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5581722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": instances}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0d079e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    0\n",
      "  ],\n",
      "  \"deployedModelId\": \"4876048196163338240\",\n",
      "  \"model\": \"projects/633472233130/locations/us-central1/models/model_04b_fraud\",\n",
      "  \"modelDisplayName\": \"04b_fraud\",\n",
      "  \"modelVersionId\": \"1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb76113",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adfee93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "[0]\n",
      "\n",
      "\n",
      "To take a quick anonymous survey, run:\n",
      "  $ gcloud survey\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b24448",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
